{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5376bc19",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Network Spectral Properties Research Framework\n",
    "Colab notebook setup for algorithm performance comparison\n",
    "\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import time\n",
    "import psutil\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from typing import Dict, Any, Tuple, List, Optional\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NetworkResearchFramework:\n",
    "    def __init__(self, db_path: str = \"network_research.db\"):\n",
    "        \"\"\"Initialize the research framework with database connection.\"\"\"\n",
    "        self.db_path = db_path\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.setup_database()\n",
    "        self.system_config_id = self.record_system_config()\n",
    "        \n",
    "    def setup_database(self):\n",
    "        \"\"\"Create database tables if they don't exist.\"\"\"\n",
    "        # Execute the schema from the previous artifact\n",
    "        schema_sql = \"\"\"\n",
    "        -- Your schema SQL here (from previous artifact)\n",
    "        \"\"\"\n",
    "        self.conn.executescript(schema_sql)\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def record_system_config(self) -> int:\n",
    "        \"\"\"Record current system configuration and return config_id.\"\"\"\n",
    "        try:\n",
    "            import scipy\n",
    "            scipy_version = scipy.__version__\n",
    "        except:\n",
    "            scipy_version = \"Not installed\"\n",
    "            \n",
    "        config_data = {\n",
    "            'python_version': platform.python_version(),\n",
    "            'numpy_version': np.__version__,\n",
    "            'scipy_version': scipy_version,\n",
    "            'networkx_version': nx.__version__,\n",
    "            'cpu_info': platform.processor(),\n",
    "            'memory_gb': psutil.virtual_memory().total / (1024**3),\n",
    "            'gpu_info': self._get_gpu_info(),\n",
    "            'colab_runtime_type': self._detect_colab_runtime()\n",
    "        }\n",
    "        \n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO system_configs \n",
    "            (python_version, numpy_version, scipy_version, networkx_version, \n",
    "             cpu_info, memory_gb, gpu_info, colab_runtime_type)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", tuple(config_data.values()))\n",
    "        \n",
    "        self.conn.commit()\n",
    "        return cursor.lastrowid\n",
    "    \n",
    "    def _get_gpu_info(self) -> str:\n",
    "        \"\"\"Get GPU information if available.\"\"\"\n",
    "        try:\n",
    "            import GPUtil\n",
    "            gpus = GPUtil.getGPUs()\n",
    "            if gpus:\n",
    "                return f\"{gpus[0].name} - {gpus[0].memoryTotal}MB\"\n",
    "        except:\n",
    "            pass\n",
    "        return \"None detected\"\n",
    "    \n",
    "    def _detect_colab_runtime(self) -> str:\n",
    "        \"\"\"Detect Google Colab runtime type.\"\"\"\n",
    "        try:\n",
    "            # Check if running in Colab\n",
    "            import google.colab\n",
    "            # You could add logic here to detect runtime type\n",
    "            return \"Google Colab\"\n",
    "        except:\n",
    "            return \"Local/Other\"\n",
    "    \n",
    "    def download_network_data(self, source: str, dataset_name: str) -> str:\n",
    "        \"\"\"Download network data from various sources.\"\"\"\n",
    "        if source.lower() == 'snap':\n",
    "            return self._download_snap_data(dataset_name)\n",
    "        elif source.lower() == 'konect':\n",
    "            return self._download_konect_data(dataset_name)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported source: {source}\")\n",
    "    \n",
    "    def _download_snap_data(self, dataset_name: str) -> str:\n",
    "        \"\"\"Download from SNAP datasets.\"\"\"\n",
    "        base_url = \"http://snap.stanford.edu/data/\"\n",
    "        # Add specific dataset URLs mapping\n",
    "        dataset_urls = {\n",
    "            'facebook_combined': 'facebook_combined.txt.gz',\n",
    "            'ca_astroph': 'ca-AstroPh.txt.gz',\n",
    "            # Add more datasets as needed\n",
    "        }\n",
    "        \n",
    "        if dataset_name not in dataset_urls:\n",
    "            raise ValueError(f\"Dataset {dataset_name} not found\")\n",
    "        \n",
    "        url = base_url + dataset_urls[dataset_name]\n",
    "        local_path = f\"data/{dataset_name}.txt.gz\"\n",
    "        \n",
    "        # Create data directory\n",
    "        os.makedirs(\"data\", exist_ok=True)\n",
    "        \n",
    "        # Download file\n",
    "        response = requests.get(url)\n",
    "        with open(local_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        logger.info(f\"Downloaded {dataset_name} to {local_path}\")\n",
    "        return local_path\n",
    "    \n",
    "    def generate_synthetic_network(self, network_type: str, **params) -> Tuple[nx.Graph, Dict]:\n",
    "        \"\"\"Generate synthetic networks with specified parameters.\"\"\"\n",
    "        generation_params = params.copy()\n",
    "        \n",
    "        if network_type == 'erdos_renyi':\n",
    "            n = params.get('n', 1000)\n",
    "            p = params.get('p', 0.01)\n",
    "            G = nx.erdos_renyi_graph(n, p)\n",
    "            \n",
    "        elif network_type == 'barabasi_albert':\n",
    "            n = params.get('n', 1000)\n",
    "            m = params.get('m', 3)\n",
    "            G = nx.barabasi_albert_graph(n, m)\n",
    "            \n",
    "        elif network_type == 'watts_strogatz':\n",
    "            n = params.get('n', 1000)\n",
    "            k = params.get('k', 6)\n",
    "            p = params.get('p', 0.1)\n",
    "            G = nx.watts_strogatz_graph(n, k, p)\n",
    "            \n",
    "        elif network_type == 'stochastic_block':\n",
    "            sizes = params.get('sizes', [100, 100, 100])\n",
    "            p_matrix = params.get('p_matrix', [[0.1, 0.01, 0.01],\n",
    "                                               [0.01, 0.1, 0.01], \n",
    "                                               [0.01, 0.01, 0.1]])\n",
    "            G = nx.stochastic_block_model(sizes, p_matrix)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown network type: {network_type}\")\n",
    "        \n",
    "        return G, generation_params\n",
    "    \n",
    "    def store_network(self, G: nx.Graph, name: str, source: str, \n",
    "                     network_type: str = None, description: str = None,\n",
    "                     generation_params: Dict = None, source_url: str = None) -> int:\n",
    "        \"\"\"Store network metadata in database.\"\"\"\n",
    "        \n",
    "        # Save network to file\n",
    "        network_file = f\"data/network_{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.edgelist\"\n",
    "        os.makedirs(\"data\", exist_ok=True)\n",
    "        nx.write_edgelist(G, network_file)\n",
    "        \n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO networks \n",
    "            (name, source, source_url, network_type, is_directed, is_weighted,\n",
    "             node_count, edge_count, description, generation_params, file_path)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            name, source, source_url, network_type, G.is_directed(),\n",
    "            nx.is_weighted(G), G.number_of_nodes(), G.number_of_edges(),\n",
    "            description, json.dumps(generation_params) if generation_params else None,\n",
    "            network_file\n",
    "        ))\n",
    "        \n",
    "        self.conn.commit()\n",
    "        network_id = cursor.lastrowid\n",
    "        logger.info(f\"Stored network {name} with ID {network_id}\")\n",
    "        return network_id\n",
    "    \n",
    "    def register_algorithm(self, name: str, category: str, implementation: str,\n",
    "                          method_details: str = None, parameters: Dict = None,\n",
    "                          description: str = None) -> int:\n",
    "        \"\"\"Register an algorithm for benchmarking.\"\"\"\n",
    "        \n",
    "        # Get version info\n",
    "        version_info = self._get_library_version(implementation)\n",
    "        \n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO algorithms \n",
    "            (name, category, implementation, version, method_details, \n",
    "             parameters, description)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            name, category, implementation, version_info, method_details,\n",
    "            json.dumps(parameters) if parameters else None, description\n",
    "        ))\n",
    "        \n",
    "        self.conn.commit()\n",
    "        algorithm_id = cursor.lastrowid\n",
    "        logger.info(f\"Registered algorithm {name} with ID {algorithm_id}\")\n",
    "        return algorithm_id\n",
    "    \n",
    "    def _get_library_version(self, implementation: str) -> str:\n",
    "        \"\"\"Get version of the implementation library.\"\"\"\n",
    "        try:\n",
    "            if implementation == 'networkx':\n",
    "                return nx.__version__\n",
    "            elif implementation == 'scipy':\n",
    "                import scipy\n",
    "                return scipy.__version__\n",
    "            elif implementation == 'numpy':\n",
    "                return np.__version__\n",
    "            # Add more as needed\n",
    "        except:\n",
    "            pass\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    def run_experiment(self, network_id: int, algorithm_id: int, \n",
    "                      algorithm_func: callable, *args, **kwargs) -> int:\n",
    "        \"\"\"Run a single experiment and record results.\"\"\"\n",
    "        \n",
    "        # Load network\n",
    "        G = self._load_network(network_id)\n",
    "        \n",
    "        # Performance monitoring setup\n",
    "        process = psutil.Process()\n",
    "        start_memory = process.memory_info().rss / 1024 / 1024  # MB\n",
    "        \n",
    "        # Run algorithm with timing\n",
    "        start_time = time.time()\n",
    "        start_cpu_times = psutil.cpu_times()\n",
    "        \n",
    "        try:\n",
    "            result = algorithm_func(G, *args, **kwargs)\n",
    "            success = True\n",
    "            error_message = None\n",
    "            \n",
    "            # Extract common spectral properties from result\n",
    "            eigenvalues, eigenvectors = self._parse_spectral_result(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            success = False\n",
    "            error_message = str(e)\n",
    "            eigenvalues = None\n",
    "            eigenvectors = None\n",
    "            logger.error(f\"Algorithm failed: {e}\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        end_cpu_times = psutil.cpu_times()\n",
    "        end_memory = process.memory_info().rss / 1024 / 1024  # MB\n",
    "        \n",
    "        # Calculate metrics\n",
    "        runtime_seconds = end_time - start_time\n",
    "        memory_peak_mb = end_memory - start_memory\n",
    "        cpu_percent = (end_cpu_times.user - start_cpu_times.user) / runtime_seconds * 100\n",
    "        \n",
    "        # Calculate spectral properties if successful\n",
    "        spectral_gap = None\n",
    "        spectral_radius = None\n",
    "        algebraic_connectivity = None\n",
    "        \n",
    "        if success and eigenvalues is not None:\n",
    "            eigenvalues_sorted = sorted(eigenvalues, reverse=True)\n",
    "            spectral_radius = eigenvalues_sorted[0]\n",
    "            if len(eigenvalues_sorted) > 1:\n",
    "                spectral_gap = eigenvalues_sorted[0] - eigenvalues_sorted[1]\n",
    "                # For Laplacian, algebraic connectivity is second smallest eigenvalue\n",
    "                algebraic_connectivity = sorted(eigenvalues)[1] if len(eigenvalues) > 1 else None\n",
    "        \n",
    "        # Store experiment results\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO experiments \n",
    "            (network_id, algorithm_id, system_config_id, runtime_seconds,\n",
    "             memory_peak_mb, cpu_percent_avg, success, error_message,\n",
    "             eigenvalues, spectral_gap, spectral_radius, algebraic_connectivity)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            network_id, algorithm_id, self.system_config_id, runtime_seconds,\n",
    "            memory_peak_mb, cpu_percent, success, error_message,\n",
    "            json.dumps(eigenvalues.tolist() if eigenvalues is not None else None),\n",
    "            spectral_gap, spectral_radius, algebraic_connectivity\n",
    "        ))\n",
    "        \n",
    "        self.conn.commit()\n",
    "        experiment_id = cursor.lastrowid\n",
    "        \n",
    "        logger.info(f\"Experiment {experiment_id} completed - Runtime: {runtime_seconds:.3f}s, Success: {success}\")\n",
    "        return experiment_id\n",
    "    \n",
    "    def _load_network(self, network_id: int) -> nx.Graph:\n",
    "        \"\"\"Load network from file based on network_id.\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"SELECT file_path, is_directed FROM networks WHERE network_id = ?\", (network_id,))\n",
    "        row = cursor.fetchone()\n",
    "        \n",
    "        if not row:\n",
    "            raise ValueError(f\"Network {network_id} not found\")\n",
    "        \n",
    "        file_path, is_directed = row\n",
    "        \n",
    "        if is_directed:\n",
    "            G = nx.read_edgelist(file_path, create_using=nx.DiGraph())\n",
    "        else:\n",
    "            G = nx.read_edgelist(file_path)\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def _parse_spectral_result(self, result) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Parse different types of spectral algorithm results.\"\"\"\n",
    "        if isinstance(result, tuple) and len(result) == 2:\n",
    "            # Eigenvalues and eigenvectors\n",
    "            return result[0], result[1]\n",
    "        elif isinstance(result, np.ndarray) and result.ndim == 1:\n",
    "            # Just eigenvalues\n",
    "            return result, None\n",
    "        else:\n",
    "            # Try to extract eigenvalues from other formats\n",
    "            return None, None\n",
    "    \n",
    "    def create_visualization(self, network_id: int, layout_algorithm: str = 'spring',\n",
    "                           save_format: str = 'PNG', **layout_params) -> int:\n",
    "        \"\"\"Create and store network visualization.\"\"\"\n",
    "        \n",
    "        G = self._load_network(network_id)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Choose layout algorithm\n",
    "        if layout_algorithm == 'spring':\n",
    "            pos = nx.spring_layout(G, **layout_params)\n",
    "        elif layout_algorithm == 'spectral':\n",
    "            pos = nx.spectral_layout(G, **layout_params)\n",
    "        elif layout_algorithm == 'circular':\n",
    "            pos = nx.circular_layout(G, **layout_params)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown layout algorithm: {layout_algorithm}\")\n",
    "        \n",
    "        # Draw network\n",
    "        nx.draw(G, pos, node_size=50, node_color='lightblue', \n",
    "                edge_color='gray', alpha=0.6, with_labels=False)\n",
    "        \n",
    "        plt.title(f\"Network {network_id} - {layout_algorithm} layout\")\n",
    "        \n",
    "        # Save image\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        image_path = f\"visualizations/network_{network_id}_{layout_algorithm}_{timestamp}.{save_format.lower()}\"\n",
    "        os.makedirs(\"visualizations\", exist_ok=True)\n",
    "        \n",
    "        plt.savefig(image_path, format=save_format, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Store in database\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO visualizations \n",
    "            (network_id, layout_algorithm, image_format, image_path,\n",
    "             layout_params, width, height)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            network_id, layout_algorithm, save_format, image_path,\n",
    "            json.dumps(layout_params), 12, 8  # figure size\n",
    "        ))\n",
    "        \n",
    "        self.conn.commit()\n",
    "        viz_id = cursor.lastrowid\n",
    "        \n",
    "        logger.info(f\"Created visualization {viz_id} for network {network_id}\")\n",
    "        return viz_id\n",
    "    \n",
    "    def run_benchmark_suite(self, network_ids: List[int], algorithm_configs: List[Dict],\n",
    "                           runs_per_config: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Run comprehensive benchmark suite.\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        total_experiments = len(network_ids) * len(algorithm_configs) * runs_per_config\n",
    "        \n",
    "        logger.info(f\"Starting benchmark suite: {total_experiments} total experiments\")\n",
    "        \n",
    "        for network_id in network_ids:\n",
    "            for algo_config in algorithm_configs:\n",
    "                algorithm_id = algo_config['algorithm_id']\n",
    "                algorithm_func = algo_config['function']\n",
    "                args = algo_config.get('args', [])\n",
    "                kwargs = algo_config.get('kwargs', {})\n",
    "                \n",
    "                for run in range(runs_per_config):\n",
    "                    logger.info(f\"Running network {network_id}, algorithm {algorithm_id}, run {run+1}/{runs_per_config}\")\n",
    "                    \n",
    "                    experiment_id = self.run_experiment(\n",
    "                        network_id, algorithm_id, algorithm_func, *args, **kwargs\n",
    "                    )\n",
    "                    \n",
    "                    results.append({\n",
    "                        'experiment_id': experiment_id,\n",
    "                        'network_id': network_id,\n",
    "                        'algorithm_id': algorithm_id,\n",
    "                        'run_number': run + 1\n",
    "                    })\n",
    "        \n",
    "        logger.info(\"Benchmark suite completed\")\n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def get_performance_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Get performance summary using the database view.\"\"\"\n",
    "        return pd.read_sql_query(\"\"\"\n",
    "            SELECT * FROM algorithm_performance \n",
    "            ORDER BY node_count, algorithm_name\n",
    "        \"\"\", self.conn)\n",
    "    \n",
    "    def plot_performance_comparison(self, metric: str = 'avg_runtime'):\n",
    "        \"\"\"Create performance comparison plots.\"\"\"\n",
    "        df = self.get_performance_summary()\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Runtime vs Network Size\n",
    "        plt.subplot(2, 2, 1)\n",
    "        for algo in df['algorithm_name'].unique():\n",
    "            algo_data = df[df['algorithm_name'] == algo]\n",
    "            plt.loglog(algo_data['node_count'], algo_data[metric], 'o-', label=algo)\n",
    "        plt.xlabel('Network Size (nodes)')\n",
    "        plt.ylabel(metric.replace('_', ' ').title())\n",
    "        plt.legend()\n",
    "        plt.title(f'{metric.replace(\"_\", \" \").title()} vs Network Size')\n",
    "        \n",
    "        # Box plots by algorithm\n",
    "        plt.subplot(2, 2, 2)\n",
    "        df_melted = df.melt(id_vars=['algorithm_name'], value_vars=[metric])\n",
    "        sns.boxplot(data=df_melted, x='algorithm_name', y='value')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(f'{metric.replace(\"_\", \" \").title()} Distribution by Algorithm')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close database connection.\"\"\"\n",
    "        self.conn.close()\n",
    "\n",
    "\n",
    "# Example usage and algorithm implementations\n",
    "def networkx_adjacency_spectrum(G):\n",
    "    \"\"\"Compute adjacency spectrum using NetworkX.\"\"\"\n",
    "    return nx.adjacency_spectrum(G)\n",
    "\n",
    "def scipy_sparse_eigenvals(G, k=6):\n",
    "    \"\"\"Compute largest k eigenvalues using SciPy sparse methods.\"\"\"\n",
    "    from scipy.sparse.linalg import eigsh\n",
    "    adj_matrix = nx.adjacency_matrix(G)\n",
    "    eigenvals, eigenvecs = eigsh(adj_matrix, k=k, which='LM')\n",
    "    return eigenvals, eigenvecs\n",
    "\n",
    "def networkx_laplacian_spectrum(G):\n",
    "    \"\"\"Compute Laplacian spectrum using NetworkX.\"\"\"\n",
    "    return nx.laplacian_spectrum(G)\n",
    "\n",
    "# Initialize framework\n",
    "framework = NetworkResearchFramework()\n",
    "\n",
    "print(\"Network Research Framework initialized!\")\n",
    "print(\"Database schema created and system configuration recorded.\")\n",
    "print(f\"System config ID: {framework.system_config_id}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
